name: Databricks CI/CD

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch: {}   # allow manual runs from Actions tab

jobs:
  deploy-notebooks:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Databricks CLI (legacy v0.x)
        run: pip install databricks-cli

      # Configure the LEGACY CLI (expects ~/.databrickscfg)
      - name: Configure Databricks CLI
        shell: bash
        run: |
          set -eu
          cat > ~/.databrickscfg <<EOF
          [DEFAULT]
          host = ${{ secrets.DATABRICKS_HOST }}
          token = ${{ secrets.DATABRICKS_TOKEN }}
          EOF
          echo "Wrote ~/.databrickscfg"
          head -n1 ~/.databrickscfg   # prints only the [DEFAULT] line (no secrets)

      - name: Sanity check CLI
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          databricks --version || true
          databricks workspace ls /Shared || true

      - name: Ensure target workspace folder exists
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: databricks workspace mkdirs /Shared/cicd-practice || true

      - name: Deploy notebook(s)
        shell: bash
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          python - <<'PY'
          import json, os, subprocess
          with open("deployment.json") as f:
              spec = json.load(f)
          ext2lang = {'.py':'PYTHON', '.scala':'SCALA', '.sql':'SQL', '.r':'R'}
          for item in spec.get("notebooks", []):
              local = item["path"]
              target = item["target"]
              lang = ext2lang.get(os.path.splitext(local)[1].lower(), 'PYTHON')
              cmd = [
                  "databricks","workspace","import",
                  "--language", lang, "--format","SOURCE",
                  local, target, "--overwrite"
              ]
              print("Running:", " ".join(cmd), flush=True)
              subprocess.check_call(cmd)
          PY
